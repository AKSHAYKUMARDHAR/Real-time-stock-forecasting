{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1837a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in .\\.venv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: psycopg2-binary in .\\.venv\\lib\\site-packages (2.9.11)\n",
      "Requirement already satisfied: schedule in .\\.venv\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: python-dotenv in .\\.venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests psycopg2-binary schedule python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe58f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9be3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching last 60 days for ENGI.PA...\n",
      "\n",
      "Inserted/Updated 60 records\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import psycopg2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# =============================\n",
    "# LOAD ENV VARIABLES\n",
    "# =============================\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"ALPHA_VANTAGE_API_KEY not found in .env file\")\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"database\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\")\n",
    "}\n",
    "\n",
    "SYMBOL = \"ENGI.PA\"   # Change symbol here\n",
    "\n",
    "# =============================\n",
    "# DB CONNECTION\n",
    "# =============================\n",
    "def get_connection():\n",
    "    return psycopg2.connect(**DB_CONFIG)\n",
    "\n",
    "# =============================\n",
    "# FETCH LAST 60 DAYS\n",
    "# =============================\n",
    "def fetch_last_60_days(symbol):\n",
    "    try:\n",
    "        url = (\n",
    "            \"https://www.alphavantage.co/query\"\n",
    "            f\"?function=TIME_SERIES_DAILY\"\n",
    "            f\"&symbol={symbol}\"\n",
    "            f\"&outputsize=compact\"\n",
    "            f\"&apikey={API_KEY}\"\n",
    "        )\n",
    "\n",
    "        response = requests.get(url, timeout=10)\n",
    "        data = response.json()\n",
    "\n",
    "        if \"Time Series (Daily)\" not in data:\n",
    "            print(\"API Response:\", data)\n",
    "            return None\n",
    "\n",
    "        series = data[\"Time Series (Daily)\"]\n",
    "\n",
    "        # Get latest 60 dates\n",
    "        sorted_dates = sorted(series.keys(), reverse=True)[:60]\n",
    "\n",
    "        candles = []\n",
    "\n",
    "        for date_str in sorted_dates:\n",
    "            daily = series[date_str]\n",
    "\n",
    "            candles.append({\n",
    "                \"symbol\": symbol,\n",
    "                \"open\": float(daily[\"1. open\"]),\n",
    "                \"high\": float(daily[\"2. high\"]),\n",
    "                \"low\": float(daily[\"3. low\"]),\n",
    "                \"close\": float(daily[\"4. close\"]),\n",
    "                \"volume\": int(daily[\"5. volume\"]),\n",
    "                \"timestamp\": datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "            })\n",
    "\n",
    "        return candles\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Fetch error:\", e)\n",
    "        return None\n",
    "\n",
    "# =============================\n",
    "# SAVE MULTIPLE ROWS\n",
    "# =============================\n",
    "def save_multiple_to_db(candles):\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO stock_prices_daily\n",
    "            (symbol, open, high, low, close, volume, timestamp)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (symbol, timestamp) DO UPDATE SET\n",
    "                open = EXCLUDED.open,\n",
    "                high = EXCLUDED.high,\n",
    "                low = EXCLUDED.low,\n",
    "                close = EXCLUDED.close,\n",
    "                volume = EXCLUDED.volume;\n",
    "        \"\"\"\n",
    "\n",
    "        for candle in candles:\n",
    "            cur.execute(insert_query, (\n",
    "                candle[\"symbol\"],\n",
    "                candle[\"open\"],\n",
    "                candle[\"high\"],\n",
    "                candle[\"low\"],\n",
    "                candle[\"close\"],\n",
    "                candle[\"volume\"],\n",
    "                candle[\"timestamp\"]\n",
    "            ))\n",
    "\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "        print(f\"Inserted/Updated {len(candles)} records\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Database insert error:\", e)\n",
    "\n",
    "# =============================\n",
    "# MAIN\n",
    "# =============================\n",
    "def main():\n",
    "    print(f\"Fetching last 60 days for {SYMBOL}...\\n\")\n",
    "\n",
    "    candles = fetch_last_60_days(SYMBOL)\n",
    "\n",
    "    if candles:\n",
    "        save_multiple_to_db(candles)\n",
    "        print(\"Done.\")\n",
    "    else:\n",
    "        print(\"No data fetched.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971859ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LSTM model...\n",
      "Loading scaler...\n",
      "Starting DAILY ingestion + LSTM prediction...\n",
      "\n",
      "Saved: ENGI.PA at 2026-02-18\n",
      "\n",
      "Predicted NEXT DAY close for ENGI.PA: 26.56\n",
      "\n",
      "Sleeping 24 hours...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import psycopg2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ==========================================\n",
    "# LOAD ENVIRONMENT VARIABLES\n",
    "# ==========================================\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"ALPHA_VANTAGE_API_KEY not found in .env file\")\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"database\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\")\n",
    "}\n",
    "\n",
    "STOCKS = [\"ENGI.PA\"]\n",
    "N_PAST = 60\n",
    "\n",
    "# ==========================================\n",
    "# LOAD MODEL + SCALER\n",
    "# ==========================================\n",
    "print(\"Loading LSTM model...\")\n",
    "model = load_model(\"lstm_model.h5\", compile=False)\n",
    "\n",
    "print(\"Loading scaler...\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# ==========================================\n",
    "# DATABASE CONNECTION\n",
    "# ==========================================\n",
    "def get_connection():\n",
    "    return psycopg2.connect(**DB_CONFIG)\n",
    "\n",
    "# ==========================================\n",
    "# FETCH LATEST DAILY CANDLE\n",
    "# ==========================================\n",
    "def fetch_latest_candle(symbol):\n",
    "    try:\n",
    "        url = (\n",
    "            \"https://www.alphavantage.co/query\"\n",
    "            f\"?function=TIME_SERIES_DAILY\"\n",
    "            f\"&symbol={symbol}\"\n",
    "            f\"&outputsize=compact\"\n",
    "            f\"&apikey={API_KEY}\"\n",
    "        )\n",
    "\n",
    "        response = requests.get(url, timeout=10)\n",
    "        data = response.json()\n",
    "\n",
    "        if \"Time Series (Daily)\" not in data:\n",
    "            print(\"API Response:\", data)\n",
    "            return None\n",
    "\n",
    "        series = data[\"Time Series (Daily)\"]\n",
    "\n",
    "        # Get most recent trading day\n",
    "        latest_date = sorted(series.keys(), reverse=True)[0]\n",
    "        latest = series[latest_date]\n",
    "\n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"open\": float(latest[\"1. open\"]),\n",
    "            \"high\": float(latest[\"2. high\"]),\n",
    "            \"low\": float(latest[\"3. low\"]),\n",
    "            \"close\": float(latest[\"4. close\"]),\n",
    "            \"volume\": int(latest[\"5. volume\"]),\n",
    "            \"timestamp\": datetime.strptime(latest_date, \"%Y-%m-%d\").date()\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Fetch error:\", e)\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# SAVE CANDLE TO DATABASE\n",
    "# ==========================================\n",
    "def save_to_db(data):\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO stock_prices_daily\n",
    "            (symbol, open, high, low, close, volume, timestamp)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (symbol, timestamp) DO NOTHING;\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(insert_query, (\n",
    "            data[\"symbol\"],\n",
    "            data[\"open\"],\n",
    "            data[\"high\"],\n",
    "            data[\"low\"],\n",
    "            data[\"close\"],\n",
    "            data[\"volume\"],\n",
    "            data[\"timestamp\"]\n",
    "        ))\n",
    "\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "        print(f\"Saved: {data['symbol']} at {data['timestamp']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Database insert error:\", e)\n",
    "\n",
    "# ==========================================\n",
    "# FETCH LAST 60 DAYS FROM DB\n",
    "# ==========================================\n",
    "def get_last_n_days(symbol, n=N_PAST):\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        query = \"\"\"\n",
    "            SELECT open, high, low, close\n",
    "            FROM stock_prices_daily\n",
    "            WHERE symbol = %s\n",
    "            ORDER BY timestamp DESC\n",
    "            LIMIT %s;\n",
    "        \"\"\"\n",
    "\n",
    "        cur.execute(query, (symbol, n))\n",
    "        rows = cur.fetchall()\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "        if len(rows) < n:\n",
    "            print(\"Not enough historical data for prediction\")\n",
    "            return None\n",
    "\n",
    "        rows.reverse()\n",
    "\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(rows, columns=['open','high','low','close'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"DB fetch error:\", e)\n",
    "        return None\n",
    "# ==========================================\n",
    "# PREDICT NEXT DAY CLOSE\n",
    "# ==========================================\n",
    "def predict_next_day(symbol):\n",
    "    data = get_last_n_days(symbol)\n",
    "\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    # Scale\n",
    "    scaled_data = scaler.transform(data)\n",
    "\n",
    "    # Reshape for LSTM\n",
    "    X_input = scaled_data.reshape(1, N_PAST, 4)\n",
    "\n",
    "    # Predict\n",
    "    prediction_scaled = model.predict(X_input, verbose=0)\n",
    "\n",
    "    # Inverse scale (close is index 3)\n",
    "    dummy = np.zeros((1, 4))\n",
    "    dummy[0, 3] = prediction_scaled[0, 0]\n",
    "\n",
    "    predicted_price = scaler.inverse_transform(dummy)[0, 3]\n",
    "\n",
    "    print(f\"\\nPredicted NEXT DAY close for {symbol}: {predicted_price:.2f}\\n\")\n",
    "\n",
    "    return predicted_price\n",
    "    \n",
    "\n",
    "# ==========================================\n",
    "# MAIN LOOP\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(\"Starting DAILY ingestion + LSTM prediction...\\n\")\n",
    "\n",
    "    while True:\n",
    "        for symbol in STOCKS:\n",
    "            data = fetch_latest_candle(symbol)\n",
    "\n",
    "            if data:\n",
    "                save_to_db(data)\n",
    "                predict_next_day(symbol)\n",
    "\n",
    "        print(\"Sleeping 24 hours...\\n\")\n",
    "        time.sleep(86400)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d7bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
